{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "bilstm_crf_thai2fit_nerc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install Library\n",
        "tensorflow version 1.13.1\n",
        "\n",
        "keras 2.2.4\n",
        "\n",
        "keras-contrib\n",
        "\n",
        "pythainlp (thai2fit)\n"
      ],
      "metadata": {
        "id": "bt4dJHqOS-g-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-22T14:04:17.664238Z",
          "iopub.execute_input": "2022-02-22T14:04:17.665217Z",
          "iopub.status.idle": "2022-02-22T14:04:30.902887Z",
          "shell.execute_reply.started": "2022-02-22T14:04:17.665047Z",
          "shell.execute_reply": "2022-02-22T14:04:30.901824Z"
        },
        "trusted": true,
        "id": "F_HUacBry1ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==1.13.1\n",
        "import tensorflow"
      ],
      "metadata": {
        "id": "1smqhyUvy1dU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras==2.2.4\n",
        "import keras"
      ],
      "metadata": {
        "id": "5Naadc-d519_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pythainlp"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-22T14:05:18.551777Z",
          "iopub.execute_input": "2022-02-22T14:05:18.552830Z",
          "iopub.status.idle": "2022-02-22T14:05:27.606833Z",
          "shell.execute_reply.started": "2022-02-22T14:05:18.552777Z",
          "shell.execute_reply": "2022-02-22T14:05:27.605711Z"
        },
        "trusted": true,
        "id": "Bw-fOtcXy1c1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Library"
      ],
      "metadata": {
        "id": "UcccwE2-Te2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save / Load File\n",
        "import pickle\n",
        "\n",
        "# Plot Graph\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sklearn Report\n",
        "import sklearn\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from itertools import chain\n",
        "\n",
        "# Load Vectors\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# Utility\n",
        "import numpy as np\n",
        "\n",
        "# Model Utility\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Keras Model\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model, Input\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Conv1D\n",
        "from keras.layers import Bidirectional, concatenate, SpatialDropout1D, GlobalMaxPooling1D\n",
        "from keras_contrib.layers import CRF\n",
        "from keras.callbacks import ModelCheckpoint , EarlyStopping"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2022-02-22T14:04:30.904736Z",
          "iopub.execute_input": "2022-02-22T14:04:30.905057Z",
          "iopub.status.idle": "2022-02-22T14:04:37.591458Z",
          "shell.execute_reply.started": "2022-02-22T14:04:30.905006Z",
          "shell.execute_reply": "2022-02-22T14:04:37.590473Z"
        },
        "trusted": true,
        "id": "5Zw-j-0Sy1cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download and Thai2fit word vector"
      ],
      "metadata": {
        "id": "whtdnVw2T4-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#LST20 data\n",
        "with open('train_sent_lst20.data', 'rb') as filehandle:\n",
        "    train_sent = pickle.load(filehandle)\n",
        "with open('train_ner_lst20.data', 'rb') as filehandle:\n",
        "    train_ner = pickle.load(filehandle)\n",
        "with open('eval_sent_lst20.data', 'rb') as filehandle:\n",
        "    eval_sent = pickle.load(filehandle)\n",
        "with open('eval_ner_lst20.data', 'rb') as filehandle:\n",
        "    eval_ner = pickle.load(filehandle)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-22T14:04:37.593485Z",
          "iopub.execute_input": "2022-02-22T14:04:37.593875Z",
          "iopub.status.idle": "2022-02-22T14:04:39.644851Z",
          "shell.execute_reply.started": "2022-02-22T14:04:37.593825Z",
          "shell.execute_reply": "2022-02-22T14:04:39.643989Z"
        },
        "trusted": true,
        "id": "7s0Ws8Ixy1cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pythainlp import word_vector\n",
        "thai2fit_model = word_vector.get_model()\n",
        "thai2fit_weight = thai2fit_model.vectors"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-22T14:05:27.610851Z",
          "iopub.execute_input": "2022-02-22T14:05:27.611165Z",
          "iopub.status.idle": "2022-02-22T14:05:34.197915Z",
          "shell.execute_reply.started": "2022-02-22T14:05:27.611130Z",
          "shell.execute_reply": "2022-02-22T14:05:34.196898Z"
        },
        "trusted": true,
        "id": "HPKmCRw1y1c3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner_tags = [\n",
        "        \"O\",\n",
        "        \"B_BRN\",\n",
        "        \"B_DES\",\n",
        "        \"B_DTM\",\n",
        "        \"B_LOC\",\n",
        "        \"B_MEA\",\n",
        "        \"B_NUM\",\n",
        "        \"B_ORG\",\n",
        "        \"B_PER\",\n",
        "        \"B_TRM\",\n",
        "        \"B_TTL\",\n",
        "        \"I_BRN\",\n",
        "        \"I_DES\",\n",
        "        \"I_DTM\",\n",
        "        \"I_LOC\",\n",
        "        \"I_MEA\",\n",
        "        \"I_NUM\",\n",
        "        \"I_ORG\",\n",
        "        \"I_PER\",\n",
        "        \"I_TRM\",\n",
        "        \"I_TTL\",\n",
        "        \"E_BRN\",\n",
        "        \"E_DES\",\n",
        "        \"E_DTM\",\n",
        "        \"E_LOC\",\n",
        "        \"E_MEA\",\n",
        "        \"E_NUM\",\n",
        "        \"E_ORG\",\n",
        "        \"E_PER\",\n",
        "        \"E_TRM\",\n",
        "        \"E_TTL\",\n",
        "    ]"
      ],
      "metadata": {
        "id": "oQpRhki0jwLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dump=[]\n",
        "for i, ner_sent in enumerate(train_ner):\n",
        "    for ner in ner_sent:\n",
        "        if not (ner in ner_tags):\n",
        "            dump.append(ner_sent)\n",
        "            break"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-22T14:04:53.078677Z",
          "iopub.execute_input": "2022-02-22T14:04:53.078958Z",
          "iopub.status.idle": "2022-02-22T14:04:53.608335Z",
          "shell.execute_reply.started": "2022-02-22T14:04:53.078928Z",
          "shell.execute_reply": "2022-02-22T14:04:53.607458Z"
        },
        "trusted": true,
        "id": "WUMrP38jy1c7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ners in dump:\n",
        "    idx = train_ner.index(ners)\n",
        "    train_ner.pop(idx)\n",
        "    train_sent.pop(idx)    "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-22T14:04:58.134379Z",
          "iopub.execute_input": "2022-02-22T14:04:58.135187Z",
          "iopub.status.idle": "2022-02-22T14:04:58.942159Z",
          "shell.execute_reply.started": "2022-02-22T14:04:58.135144Z",
          "shell.execute_reply": "2022-02-22T14:04:58.941228Z"
        },
        "trusted": true,
        "id": "vOJGpdg6y1c_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#limit 300 words\n",
        "for i, item in enumerate(train_sent):\n",
        "    if len(item)>300:\n",
        "        train_sent[i]=item[:300]\n",
        "        train_ner[i]=train_ner[i][:300]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-22T14:04:59.832975Z",
          "iopub.execute_input": "2022-02-22T14:04:59.833299Z",
          "iopub.status.idle": "2022-02-22T14:04:59.850139Z",
          "shell.execute_reply.started": "2022-02-22T14:04:59.833268Z",
          "shell.execute_reply": "2022-02-22T14:04:59.848967Z"
        },
        "trusted": true,
        "id": "wciSlHJey1dB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare dictionary\n",
        "\n",
        "word_list=[]\n",
        "ner_list=[]\n",
        "thai2dict = {}\n",
        "\n",
        "for sent in train_sent:\n",
        "    for word in sent:\n",
        "        word_list.append(word)\n",
        "for ners in train_ner:\n",
        "    for ner in ners:\n",
        "        ner_list.append(ner)        \n",
        "        \n",
        "for word in thai2fit_model.index2word:\n",
        "    thai2dict[word] = thai2fit_model[word]\n",
        "\n",
        "word_list.append(\"pad\")\n",
        "word_list.append(\"unknown\") #Special Token for Unknown words (\"UNK\")\n",
        "ner_list.append(\"pad\")\n",
        "\n",
        "all_words = sorted(set(word_list))\n",
        "all_ner = sorted(set(ner_list))\n",
        "all_thai2dict = sorted(set(thai2dict))\n",
        "\n",
        "word_to_ix = dict((c, i) for i, c in enumerate(all_words)) #convert word to index \n",
        "ner_to_ix = dict((c, i) for i, c in enumerate(all_ner)) #convert ner to index\n",
        "thai2dict_to_ix = dict((c, i) for i, c in enumerate(thai2dict)) #convert thai2fit to index \n",
        "\n",
        "ix_to_word = dict((v,k) for k,v in word_to_ix.items()) #convert index to word\n",
        "ix_to_ner = dict((v,k) for k,v in ner_to_ix.items())  #convert index to ner\n",
        "ix_to_thai2dict = dict((v,k) for k,v in thai2dict_to_ix.items())  #convert index to thai2fit\n",
        "\n",
        "n_word = len(word_to_ix)\n",
        "n_tag = len(ner_to_ix)\n",
        "n_thai2dict = len(thai2dict_to_ix)\n",
        "print(n_word)\n",
        "print(n_tag)\n",
        "print(n_thai2dict)\n",
        "print(ner_to_ix)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-22T14:05:39.370204Z",
          "iopub.execute_input": "2022-02-22T14:05:39.371326Z",
          "iopub.status.idle": "2022-02-22T14:05:40.703622Z",
          "shell.execute_reply.started": "2022-02-22T14:05:39.371260Z",
          "shell.execute_reply": "2022-02-22T14:05:40.702537Z"
        },
        "trusted": true,
        "id": "R1wO2ND8y1dF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('nerdict.pickle', 'wb') as nerdict:\n",
        "    pickle.dump(ner_to_ix, nerdict)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-22T14:06:05.657211Z",
          "iopub.execute_input": "2022-02-22T14:06:05.657535Z",
          "iopub.status.idle": "2022-02-22T14:06:05.662526Z",
          "shell.execute_reply.started": "2022-02-22T14:06:05.657493Z",
          "shell.execute_reply": "2022-02-22T14:06:05.661362Z"
        },
        "trusted": true,
        "id": "HgsKrbQuy1dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Building"
      ],
      "metadata": {
        "id": "0WY5jrCzU3Yz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 300\n",
        "#max_len_char = 30\n",
        "\n",
        "character_LSTM_unit = 32\n",
        "char_embedding_dim = 32\n",
        "main_lstm_unit = 256 ## Bidirectional 256 + 256 = 512\n",
        "lstm_recurrent_dropout = 0.5\n",
        "\n",
        "train_batch_size = 32\n",
        "train_epochs = 50"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-22T14:05:47.985587Z",
          "iopub.execute_input": "2022-02-22T14:05:47.986356Z",
          "iopub.status.idle": "2022-02-22T14:05:47.991443Z",
          "shell.execute_reply.started": "2022-02-22T14:05:47.986308Z",
          "shell.execute_reply": "2022-02-22T14:05:47.990318Z"
        },
        "trusted": true,
        "id": "ydpb5PlVy1dO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_sequence_word(input_text):\n",
        "    idxs = list()\n",
        "    for word in input_text:\n",
        "        if word in thai2dict:\n",
        "            idxs.append(thai2dict_to_ix[word])\n",
        "        else:\n",
        "            idxs.append(thai2dict_to_ix[\"unknown\"]) #Use UNK tag for unknown word\n",
        "    return idxs\n",
        "\n",
        "def prepare_sequence_target(input_label):\n",
        "    idxs = list()\n",
        "    for word in input_label:\n",
        "        if word in ner_to_ix.keys():\n",
        "            idxs.append(ner_to_ix[word])\n",
        "        else:\n",
        "            idxs.append(ner_to_ix[\"O\"])\n",
        "    return idxs"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-22T14:05:50.935893Z",
          "iopub.execute_input": "2022-02-22T14:05:50.936232Z",
          "iopub.status.idle": "2022-02-22T14:05:50.943775Z",
          "shell.execute_reply.started": "2022-02-22T14:05:50.936194Z",
          "shell.execute_reply": "2022-02-22T14:05:50.942637Z"
        },
        "trusted": true,
        "id": "m2_tAoy_y1dQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Word Training\n",
        "X_word_tr = [prepare_sequence_word(s) for s in train_sent]\n",
        "X_word_tr = pad_sequences(maxlen=max_len, sequences=X_word_tr, value=thai2dict_to_ix[\"pad\"], padding='post', truncating='post')\n",
        "\n",
        "# Sequence Label Training\n",
        "y_tr = [prepare_sequence_target(s) for s in train_ner]\n",
        "y_tr = pad_sequences(maxlen=max_len, sequences=y_tr, value=ner_to_ix[\"pad\"], padding='post', truncating='post')\n",
        "y_tr = [to_categorical(i, num_classes=n_tag) for i in y_tr]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-22T14:05:51.738966Z",
          "iopub.execute_input": "2022-02-22T14:05:51.739291Z",
          "iopub.status.idle": "2022-02-22T14:05:58.593953Z",
          "shell.execute_reply.started": "2022-02-22T14:05:51.739259Z",
          "shell.execute_reply": "2022-02-22T14:05:58.592976Z"
        },
        "trusted": true,
        "id": "nE4YO1HYy1dR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_word_ev = [prepare_sequence_word(s) for s in eval_sent]\n",
        "X_word_ev = pad_sequences(maxlen=max_len, sequences=X_word_ev, value=thai2dict_to_ix[\"pad\"], padding='post', truncating='post')\n",
        "\n",
        "y_ev = [prepare_sequence_target(s) for s in eval_ner]\n",
        "y_ev = pad_sequences(maxlen=max_len, sequences=y_ev, value=ner_to_ix[\"pad\"], padding='post', truncating='post')\n",
        "y_ev = [to_categorical(i, num_classes=n_tag) for i in y_ev]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-22T14:03:19.552527Z",
          "iopub.execute_input": "2022-02-22T14:03:19.552812Z"
        },
        "trusted": true,
        "id": "-9KNn0fhy1dS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Word Input\n",
        "word_in = Input(shape=(max_len,), name='word_input_')\n",
        "\n",
        "# Word Embedding Using Thai2Fit\n",
        "word_embeddings = Embedding(input_dim=n_thai2dict,\n",
        "                            output_dim=300,\n",
        "                            weights = [thai2fit_weight],input_length=max_len,\n",
        "                            mask_zero=False,\n",
        "                            name='word_embedding', trainable=False)(word_in)\n",
        "\n",
        "all_word_embeddings = SpatialDropout1D(0.3)(word_embeddings)\n",
        "\n",
        "# BiLSTM\n",
        "main_lstm = Bidirectional(LSTM(units=main_lstm_unit, return_sequences=True,\n",
        "                               recurrent_dropout=lstm_recurrent_dropout))(all_word_embeddings)\n",
        "main_lstm = TimeDistributed(Dense(50, activation=\"relu\"))(main_lstm)\n",
        "\n",
        "# CRF\n",
        "crf = CRF(n_tag)  # CRF layer\n",
        "out = crf(main_lstm)  # output\n",
        "\n",
        "# Model\n",
        "model = Model(word_in,out)\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=crf.loss_function, metrics=[crf.accuracy])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-22T14:07:59.364916Z",
          "iopub.execute_input": "2022-02-22T14:07:59.365372Z",
          "iopub.status.idle": "2022-02-22T14:07:59.937881Z",
          "shell.execute_reply.started": "2022-02-22T14:07:59.365339Z",
          "shell.execute_reply": "2022-02-22T14:07:59.936574Z"
        },
        "trusted": true,
        "id": "ph9fGbrZy1dS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "Q3DI59Q-U8XF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping= EarlyStopping(monitor='val_crf_viterbi_accuracy', min_delta=0, patience=5, verbose=0, mode='max')\n",
        "\n",
        "filepath=\"bilstm_crf_best_weight.h5\"\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_crf_viterbi_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "callbacks_list = [early_stopping,checkpoint]"
      ],
      "metadata": {
        "id": "1NgypMrt5kF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_word_tr, np.array(y_tr), batch_size=train_batch_size, epochs=15, verbose=1,callbacks=callbacks_list, validation_split=0.05)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-22T14:11:05.949989Z",
          "iopub.execute_input": "2022-02-22T14:11:05.950994Z"
        },
        "trusted": true,
        "id": "IpIH0MUey1dT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize loss and accuracy"
      ],
      "metadata": {
        "id": "ItOVN2EVVClU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure(figsize=(12,12))\n",
        "plt.plot(hist[\"crf_viterbi_accuracy\"])\n",
        "plt.plot(hist[\"val_crf_viterbi_accuracy\"])\n",
        "plt.savefig('bilstm_crf_accuracy.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_QHOlYoh5wEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure(figsize=(12,12))\n",
        "plt.plot(hist[\"loss\"])\n",
        "plt.plot(hist[\"val_loss\"])\n",
        "plt.savefig('bilstm_crf_loss.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-DZFNKBz7T5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction and Evaluation"
      ],
      "metadata": {
        "id": "2E_kvuw2VK7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_model = model.predict(X_word_ev, verbose=1)"
      ],
      "metadata": {
        "id": "oK0UD89kVMcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "for i in range(0,len(pred_model)):\n",
        "    try:\n",
        "        out = np.argmax(pred_model[i], axis=-1)\n",
        "        true = np.argmax(y_ev[i], axis=-1)\n",
        "        revert_pred=[ix_to_ner[i] for i in out]\n",
        "        revert_true=[ix_to_ner[i] for i in true]\n",
        "        y_pred.append(revert_pred)\n",
        "        y_true.append(revert_true)\n",
        "    except:\n",
        "        print (i)"
      ],
      "metadata": {
        "id": "tAFEdI_1VOOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ner_classification_report(y_true, y_pred):\n",
        " \n",
        "    lb = LabelBinarizer()\n",
        "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
        "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
        "    tagset = list(sorted(set(lb.classes_)))\n",
        "    tagset = tagset[:-2]\n",
        "    print(tagset)\n",
        "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
        "    \n",
        "    return classification_report(\n",
        "        y_true_combined,\n",
        "        y_pred_combined,\n",
        "        labels = [class_indices[cls] for cls in tagset],\n",
        "        target_names = tagset,\n",
        "        digits=4\n",
        "    )"
      ],
      "metadata": {
        "id": "r408F1jgVZJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ner_classification_report(y_true,y_pred))"
      ],
      "metadata": {
        "id": "DivdLjaRVc_Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}